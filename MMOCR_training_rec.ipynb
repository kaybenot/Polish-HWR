{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMOCR Text Recognition Training (SATRN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check NVCC and GCC compiler version. If GCC is missing, install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Thu_Nov_18_09:45:30_PST_2021\n",
      "Cuda compilation tools, release 11.5, V11.5.119\n",
      "Build cuda_11.5.r11.5/compiler.30672275_0\n",
      "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependecies should be installed using **MMOCR_Installation.ipynb** file!  \n",
    "  \n",
    "Check Installed Dependencies Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118 True\n",
      "3.1.0\n",
      "2.0.1\n",
      "11.7\n",
      "GCC 9.3\n",
      "1.0.1\n",
      "CITATION.cff\t configs      docker\t       projects\t\t setup.py\n",
      "LICENSE\t\t data\t      docs\t       requirements\t tests\n",
      "MANIFEST.in\t dataset_zoo  mmocr\t       requirements.txt  tools\n",
      "README.md\t demo\t      mmocr.egg-info   resources\n",
      "README_zh-CN.md  dicts\t      model-index.yml  setup.cfg\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "import mmcv\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(mmcv.__version__)\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "# Check mmocr installation\n",
    "import mmocr\n",
    "print(mmocr.__version__)\n",
    "\n",
    "!ls mmocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration file which SATRN custom config should be based on. This lines were used for previous config manipulations in python code but support for training model from python code has been abandoned (I think)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile(\"./mmocr/configs/textrecog/satrn/satrn_shallow_5e_st_mj.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/23 17:13:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1181186296\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 11.5, V11.5.119\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.0.0+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.1+cu118\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1181186296\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/23 17:13:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=512)\n",
      "cute80_textrecog_data_root = 'data/cute80'\n",
      "cute80_textrecog_test = dict(\n",
      "    ann_file='textrecog_test.json',\n",
      "    data_root='data/rec',\n",
      "    pipeline=None,\n",
      "    test_mode=True,\n",
      "    type='OCRDataset')\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffer=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(\n",
      "        draw_gt=False,\n",
      "        draw_pred=False,\n",
      "        enable=False,\n",
      "        interval=1,\n",
      "        show=False,\n",
      "        type='VisualizationHook'))\n",
      "default_scope = 'mmocr'\n",
      "dictionary = dict(\n",
      "    dict_file=\n",
      "    '/home/kaybenot/MMOCR/mmocr/configs/textrecog/satrn/../../../dicts/english_digits_symbols.txt',\n",
      "    same_start_end=True,\n",
      "    type='Dictionary',\n",
      "    with_end=True,\n",
      "    with_padding=True,\n",
      "    with_start=True,\n",
      "    with_unknown=True)\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "gpu_ids = range(0, 1)\n",
      "launcher = 'none'\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)\n",
      "model = dict(\n",
      "    backbone=dict(hidden_dim=512, input_channels=3, type='ShallowCNN'),\n",
      "    data_preprocessor=dict(\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='TextRecogDataPreprocessor'),\n",
      "    decoder=dict(\n",
      "        d_embedding=512,\n",
      "        d_inner=2048,\n",
      "        d_k=64,\n",
      "        d_model=512,\n",
      "        d_v=64,\n",
      "        dictionary=dict(\n",
      "            dict_file=\n",
      "            '/home/kaybenot/MMOCR/mmocr/configs/textrecog/satrn/../../../dicts/english_digits_symbols.txt',\n",
      "            same_start_end=True,\n",
      "            type='Dictionary',\n",
      "            with_end=True,\n",
      "            with_padding=True,\n",
      "            with_start=True,\n",
      "            with_unknown=True),\n",
      "        max_seq_len=25,\n",
      "        module_loss=dict(\n",
      "            flatten=True, ignore_first_char=True, type='CEModuleLoss'),\n",
      "        n_head=8,\n",
      "        n_layers=6,\n",
      "        postprocessor=dict(type='AttentionPostprocessor'),\n",
      "        type='NRTRDecoder'),\n",
      "    encoder=dict(\n",
      "        d_inner=2048,\n",
      "        d_k=64,\n",
      "        d_model=512,\n",
      "        d_v=64,\n",
      "        dropout=0.1,\n",
      "        n_head=8,\n",
      "        n_layers=12,\n",
      "        n_position=100,\n",
      "        type='SATRNEncoder'),\n",
      "    type='SATRN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0003, type='Adam'), type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(end=5, milestones=[\n",
      "        3,\n",
      "        4,\n",
      "    ], type='MultiStepLR'),\n",
      "]\n",
      "randomness = dict(seed=None)\n",
      "resume = False\n",
      "seed = 0\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        datasets=[\n",
      "            dict(\n",
      "                ann_file='textrecog_test.json',\n",
      "                data_root='data/rec',\n",
      "                pipeline=None,\n",
      "                test_mode=True,\n",
      "                type='OCRDataset'),\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                100,\n",
      "                32,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadOCRAnnotations', with_text=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                type='PackTextRecogInputs'),\n",
      "        ],\n",
      "        type='ConcatDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_dataset = dict(\n",
      "    datasets=[\n",
      "        dict(\n",
      "            ann_file='textrecog_test.json',\n",
      "            data_root='data/rec',\n",
      "            pipeline=None,\n",
      "            test_mode=True,\n",
      "            type='OCRDataset'),\n",
      "    ],\n",
      "    pipeline=[\n",
      "        dict(type='LoadImageFromFile'),\n",
      "        dict(keep_ratio=False, scale=(\n",
      "            100,\n",
      "            32,\n",
      "        ), type='Resize'),\n",
      "        dict(type='LoadOCRAnnotations', with_text=True),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'valid_ratio',\n",
      "            ),\n",
      "            type='PackTextRecogInputs'),\n",
      "    ],\n",
      "    type='ConcatDataset')\n",
      "test_evaluator = dict(\n",
      "    dataset_prefixes=[\n",
      "        'CUTE80',\n",
      "        'IIIT5K',\n",
      "        'SVT',\n",
      "        'SVTP',\n",
      "        'IC13',\n",
      "        'IC15',\n",
      "    ],\n",
      "    metrics=[\n",
      "        dict(\n",
      "            mode=[\n",
      "                'exact',\n",
      "                'ignore_case',\n",
      "                'ignore_case_symbol',\n",
      "            ],\n",
      "            type='WordMetric'),\n",
      "        dict(type='CharMetric'),\n",
      "    ],\n",
      "    type='MultiDatasetsEvaluator')\n",
      "test_list = [\n",
      "    dict(\n",
      "        ann_file='textrecog_test.json',\n",
      "        data_root='data/rec',\n",
      "        pipeline=None,\n",
      "        test_mode=True,\n",
      "        type='OCRDataset'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        100,\n",
      "        32,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadOCRAnnotations', with_text=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'valid_ratio',\n",
      "        ),\n",
      "        type='PackTextRecogInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=20, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=128,\n",
      "    dataset=dict(\n",
      "        datasets=[\n",
      "            dict(\n",
      "                ann_file='textrecog_train.json',\n",
      "                data_root='data/rec',\n",
      "                pipeline=None,\n",
      "                type='OCRDataset'),\n",
      "            dict(\n",
      "                ann_file='textrecog_train.json',\n",
      "                data_root='data/rec',\n",
      "                pipeline=None,\n",
      "                type='OCRDataset'),\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
      "            dict(type='LoadOCRAnnotations', with_text=True),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                100,\n",
      "                32,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                type='PackTextRecogInputs'),\n",
      "        ],\n",
      "        type='ConcatDataset'),\n",
      "    num_workers=24,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_dataset = dict(\n",
      "    datasets=[\n",
      "        dict(\n",
      "            ann_file='textrecog_train.json',\n",
      "            data_root='data/rec',\n",
      "            pipeline=None,\n",
      "            type='OCRDataset'),\n",
      "        dict(\n",
      "            ann_file='textrecog_train.json',\n",
      "            data_root='data/rec',\n",
      "            pipeline=None,\n",
      "            type='OCRDataset'),\n",
      "    ],\n",
      "    pipeline=[\n",
      "        dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
      "        dict(type='LoadOCRAnnotations', with_text=True),\n",
      "        dict(keep_ratio=False, scale=(\n",
      "            100,\n",
      "            32,\n",
      "        ), type='Resize'),\n",
      "        dict(\n",
      "            meta_keys=(\n",
      "                'img_path',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'valid_ratio',\n",
      "            ),\n",
      "            type='PackTextRecogInputs'),\n",
      "    ],\n",
      "    type='ConcatDataset')\n",
      "train_list = [\n",
      "    dict(\n",
      "        ann_file='textrecog_train.json',\n",
      "        data_root='data/rec',\n",
      "        pipeline=None,\n",
      "        type='OCRDataset'),\n",
      "    dict(\n",
      "        ann_file='textrecog_train.json',\n",
      "        data_root='data/rec',\n",
      "        pipeline=None,\n",
      "        type='OCRDataset'),\n",
      "]\n",
      "train_pipeline = [\n",
      "    dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
      "    dict(type='LoadOCRAnnotations', with_text=True),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        100,\n",
      "        32,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'valid_ratio',\n",
      "        ),\n",
      "        type='PackTextRecogInputs'),\n",
      "]\n",
      "tta_model = dict(type='EncoderDecoderRecognizerTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
      "                    true_transforms=[\n",
      "                        dict(\n",
      "                            args=[\n",
      "                                dict(cls='Rot90', k=0, keep_size=False),\n",
      "                            ],\n",
      "                            type='ImgAugWrapper'),\n",
      "                    ],\n",
      "                    type='ConditionApply'),\n",
      "                dict(\n",
      "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
      "                    true_transforms=[\n",
      "                        dict(\n",
      "                            args=[\n",
      "                                dict(cls='Rot90', k=1, keep_size=False),\n",
      "                            ],\n",
      "                            type='ImgAugWrapper'),\n",
      "                    ],\n",
      "                    type='ConditionApply'),\n",
      "                dict(\n",
      "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
      "                    true_transforms=[\n",
      "                        dict(\n",
      "                            args=[\n",
      "                                dict(cls='Rot90', k=3, keep_size=False),\n",
      "                            ],\n",
      "                            type='ImgAugWrapper'),\n",
      "                    ],\n",
      "                    type='ConditionApply'),\n",
      "            ],\n",
      "            [\n",
      "                dict(keep_ratio=False, scale=(\n",
      "                    100,\n",
      "                    32,\n",
      "                ), type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadOCRAnnotations', with_text=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'valid_ratio',\n",
      "                    ),\n",
      "                    type='PackTextRecogInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        datasets=[\n",
      "            dict(\n",
      "                ann_file='textrecog_test.json',\n",
      "                data_root='data/rec',\n",
      "                pipeline=None,\n",
      "                test_mode=True,\n",
      "                type='OCRDataset'),\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                100,\n",
      "                32,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadOCRAnnotations', with_text=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                type='PackTextRecogInputs'),\n",
      "        ],\n",
      "        type='ConcatDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    dataset_prefixes=[\n",
      "        'CUTE80',\n",
      "        'IIIT5K',\n",
      "        'SVT',\n",
      "        'SVTP',\n",
      "        'IC13',\n",
      "        'IC15',\n",
      "    ],\n",
      "    metrics=[\n",
      "        dict(\n",
      "            mode=[\n",
      "                'exact',\n",
      "                'ignore_case',\n",
      "                'ignore_case_symbol',\n",
      "            ],\n",
      "            type='WordMetric'),\n",
      "        dict(type='CharMetric'),\n",
      "    ],\n",
      "    type='MultiDatasetsEvaluator')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='TextRecogLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/satrn_shallow_5e_st_mj/'\n",
      "\n",
      "05/23 17:13:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "05/23 17:13:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "05/23 17:13:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "05/23 17:13:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "05/23 17:13:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/kaybenot/MMOCR/work_dirs/satrn_shallow_5e_st_mj.\n",
      "/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Traceback (most recent call last):\n",
      "  File \"mmocr/tools/train.py\", line 114, in <module>\n",
      "    main()\n",
      "  File \"mmocr/tools/train.py\", line 110, in main\n",
      "    runner.train()\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/mmengine/runner/runner.py\", line 1777, in train\n",
      "    model = self.train_loop.run()  # type: ignore\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/mmengine/runner/loops.py\", line 96, in run\n",
      "    self.run_epoch()\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/mmengine/runner/loops.py\", line 112, in run_epoch\n",
      "    self.run_iter(idx, data_batch)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/mmengine/runner/loops.py\", line 128, in run_iter\n",
      "    outputs = self.runner.model.train_step(\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py\", line 114, in train_step\n",
      "    losses = self._run_forward(data, mode='loss')  # type: ignore\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py\", line 361, in _run_forward\n",
      "    results = self(**data, mode=mode)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kaybenot/MMOCR/mmocr/mmocr/models/textrecog/recognizers/base.py\", line 88, in forward\n",
      "    return self.loss(inputs, data_samples, **kwargs)\n",
      "  File \"/home/kaybenot/MMOCR/mmocr/mmocr/models/textrecog/recognizers/encoder_decoder_recognizer.py\", line 86, in loss\n",
      "    out_enc = self.encoder(feat, data_samples)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kaybenot/MMOCR/mmocr/mmocr/models/textrecog/encoders/satrn_encoder.py\", line 92, in forward\n",
      "    output = enc_layer(output, h, w, mask)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kaybenot/MMOCR/mmocr/mmocr/models/textrecog/layers/satrn_layers.py\", line 72, in forward\n",
      "    x = self.feed_forward(x)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kaybenot/MMOCR/mmocr/mmocr/models/textrecog/layers/satrn_layers.py\", line 138, in forward\n",
      "    x = self.conv1(x)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/mmcv/cnn/bricks/conv_module.py\", line 279, in forward\n",
      "    x = self.conv(x)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/kaybenot/MMOCR/.conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 8.00 GiB total capacity; 14.06 GiB already allocated; 0 bytes free; 14.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python mmocr/tools/train.py config/config_satrn.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
